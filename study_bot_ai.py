# -*- coding: utf-8 -*-
"""STUDY BOT AI

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RYXhVoWGlwVEWz7y1eLKtoEce39Biy8Z

Install Required Packages
"""

!pip install fastapi "uvicorn==0.20.0" nest-asyncio pyngrok
!pip install langchain langchain-community langchain-groq
!pip install pymongo python-dotenv

"""Set Up Environment Variables"""

import os

os.environ["GROQ_API_KEY"] = "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"
os.environ["MONGODB_URI"] = "mongodb+srv://ayobami9668:YOUR_MONGODB_PASSWORD@cluster0.amjy3dw.mongodb.net/?appName=Cluster0" # REPLACE WITH YOUR ACTUAL PASSWORD
os.environ["NGROK_AUTH_TOKEN"] = "YOUR_NGROK_AUTHTOKEN" # REPLACE WITH YOUR ACTUAL NGROK AUTH TOKEN

from fastapi import FastAPI
from pydantic import BaseModel
from langchain_groq import ChatGroq
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from pymongo import MongoClient
import os
import nest_asyncio

nest_asyncio.apply()

"""Initialize FastAPI"""

app = FastAPI()

import requests
from pyngrok import ngrok
import uvicorn
import threading
import time
import os

# Start uvicorn in a separate thread
def run_uvicorn():
    uvicorn.run(app, host="0.0.0.0", port=8000)

uvicorn_thread = threading.Thread(target=run_uvicorn)
uvicorn_thread.start()

# Wait a moment for the server to start
time.sleep(2)

# Set up ngrok tunnel
NGROK_AUTH_TOKEN = os.environ.get("NGROK_AUTH_TOKEN")

# Check if NGROK_AUTH_TOKEN is set in environment variables
if NGROK_AUTH_TOKEN is None or NGROK_AUTH_TOKEN == "YOUR_NGROK_AUTHTOKEN":
    print("NGROK_AUTH_TOKEN environment variable is not set or is still a placeholder. Please set it to proceed.\nExample: os.environ[\"NGROK_AUTH_TOKEN\"] = \"your_ngrok_token\"")
    # For now, we will proceed, but ngrok.connect will likely fail without it.
    # raise ValueError("NGROK_AUTH_TOKEN is not set or is a placeholder.")

# Authenticate ngrok if token is provided and is not a placeholder
public_url = None
if NGROK_AUTH_TOKEN and NGROK_AUTH_TOKEN != "YOUR_NGROK_AUTHTOKEN":
    ngrok.set_auth_token(NGROK_AUTH_TOKEN)
    public_url = ngrok.connect(8000).public_url
    print(f"Public URL: {public_url}")
else:
    print("Skipping ngrok tunnel creation as NGROK_AUTH_TOKEN is not properly configured.")


if public_url:
    url = f"{public_url}/chat"

    payload = {
        "user_id": "student1",
        "message": "Explain Newton's First Law in simple terms"
    }

    try:
        response = requests.post(url, json=payload)
        print(response.json())
    except requests.exceptions.RequestException as e:
        print(f"Error making request: {e}")
else:
    print("Cannot send request without a public ngrok URL. Please ensure NGROK_AUTH_TOKEN is correctly set and try again.")

"""Connect to MongoDB"""

mongo_client = MongoClient(os.environ["MONGODB_URI"])
db = mongo_client["study_bot"]
collection = db["chat_history"]

"""Initialize Groq LLM"""

llm = ChatGroq(
    groq_api_key=os.environ["GROQ_API_KEY"],
    model_name="llama3-8b-8192"
)

"""Request Schema"""

class ChatRequest(BaseModel):
    user_id: str
    message: str

"""System Prompt"""

SYSTEM_PROMPT = """
You are StudyBot, an AI academic assistant.
You help students understand concepts clearly and simply.
Always explain in a structured and easy-to-understand way.
If needed, provide examples.
"""

"""Helper: Get Chat History"""

def get_chat_history(user_id):
    history = collection.find({"user_id": user_id})
    messages = []
    for chat in history:
        messages.append(HumanMessage(content=chat["user_message"]))
        messages.append(AIMessage(content=chat["bot_response"]))
    return messages

""" Chat Endpoint"""

@app.post("/chat")
def chat(request: ChatRequest):
    user_id = request.user_id
    user_message = request.message

    # Retrieve history
    previous_messages = get_chat_history(user_id)

    # Build conversation
    messages = [SystemMessage(content=SYSTEM_PROMPT)]
    messages.extend(previous_messages)
    messages.append(HumanMessage(content=user_message))

    # Get response
    response = llm(messages)

    # Save to MongoDB
    collection.insert_one({
        "user_id": user_id,
        "user_message": user_message,
        "bot_response": response.content
    })

    return {"response": response.content}



# Install first if not done
!pip install fastapi uvicorn nest-asyncio

# Imports
from fastapi import FastAPI
import nest_asyncio
import uvicorn
from threading import Thread

# Apply nest_asyncio to allow uvicorn to run inside Colab
nest_asyncio.apply()

# Initialize FastAPI
app = FastAPI()

# Example route
@app.get("/")
def read_root():
    return {"message": "FastAPI is running!"}

# Run server in background thread
def run():
    uvicorn.run(app, host="0.0.0.0", port=8000)

thread = Thread(target=run)
thread.start()

# Install packages if not done already
!pip install fastapi uvicorn nest-asyncio langchain langchain-groq pymongo python-dotenv

# Imports
from fastapi import FastAPI
from pydantic import BaseModel
from langchain_groq import ChatGroq
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from pymongo import MongoClient
import os
import nest_asyncio
from threading import Thread

# Apply nest_asyncio
nest_asyncio.apply()

# Set environment variables
os.environ["GROQ_API_KEY"] = "your_groq_api_key_here"
os.environ["MONGODB_URI"] = "your_mongodb_uri_here"

# Initialize FastAPI
app = FastAPI()

# Connect to MongoDB
mongo_client = MongoClient(os.environ["MONGODB_URI"])
db = mongo_client["study_bot"]
collection = db["chat_history"]

# Initialize Groq LLM
llm = ChatGroq(
    groq_api_key=os.environ["GROQ_API_KEY"],
    model_name="llama3-8b-8192"
)

# Request schema
class ChatRequest(BaseModel):
    user_id: str
    message: str

# System prompt
SYSTEM_PROMPT = """
You are StudyBot, an AI academic assistant.
You help students understand concepts clearly and simply.
Always explain in a structured and easy-to-understand way.
If needed, provide examples.
"""

# Helper: Get Chat History
def get_chat_history(user_id):
    history = collection.find({"user_id": user_id})
    messages = []
    for chat in history:
        messages.append(HumanMessage(content=chat["user_message"]))
        messages.append(AIMessage(content=chat["bot_response"]))
    return messages

# Chat endpoint
@app.post("/chat")
def chat(request: ChatRequest):
    user_id = request.user_id
    user_message = request.message

    previous_messages = get_chat_history(user_id)

    messages = [SystemMessage(content=SYSTEM_PROMPT)]
    messages.extend(previous_messages)
    messages.append(HumanMessage(content=user_message))

    response = llm(messages)

    collection.insert_one({
        "user_id": user_id,
        "user_message": user_message,
        "bot_response": response.content
    })

    return {"response": response.content}

# Run server in background thread
def run():
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)

thread = Thread(target=run)
thread.start()

# Simple Study Bot backend code
code = """
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

# Request schema
class ChatRequest(BaseModel):
    user_id: str
    message: str

# Simple chat endpoint (just echoes the message)
@app.post("/chat")
def chat(request: ChatRequest):
    user_id = request.user_id
    user_message = request.message
    response = f"Echo: {user_message}"
    return {"response": response}

@app.get("/")
def root():
    return {"message": "StudyBot is running!"}
"""

# Save to main.py
with open("main.py", "w") as f:
    f.write(code)

# Save a simple requirements.txt
requirements = "fastapi\nuvicorn\npydantic"
with open("requirements.txt", "w") as f:
    f.write(requirements)

print("Files saved! You can now download main.py and requirements.txt.")